# This workflow triggers when code is pushed to the main branch
name: Deploy to Databricks Prod

on:
  push:
    branches:
      - main

jobs:
  deploy:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    env:
      DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
      DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}

    steps:
      - uses: actions/checkout@v3

      - name: Install Databricks CLI
        run: pip install --upgrade databricks-cli

      - name: Configure Databricks CLI
        run: |
          cat > ~/.databrickscfg << EOF
          [DEFAULT]
          host = ${{ secrets.DATABRICKS_HOST }}
          token = ${{ secrets.DATABRICKS_TOKEN }}
          EOF
      - name: Deploy notebooks to Databricks
        run: |
          set -euo pipefail
          for file in ./notebooks/*.ipynb; do
            echo "Deploying $file"
            filename=$(basename "$file" .ipynb)
            databricks workspace import "$file" "/Shared/${filename}_prod" -f SOURCE -l PYTHON --overwrite
          done

      - name: Deploy Lakeview dashboards (overwrite if exists)
        run: |
          python3 - << 'EOF'
          import requests
          import json
          import os
          import glob

          host = os.environ['DATABRICKS_HOST']
          token = os.environ['DATABRICKS_TOKEN']

          headers = {
              'Authorization': f'Bearer {token}',
              'Content-Type': 'application/json'
          }

          dashboard_files = glob.glob('./dashboards/*.lvdash.json')

          for dashboard_file in dashboard_files:
              print(f"Deploying Lakeview dashboard: {dashboard_file}")
              with open(dashboard_file, 'r') as f:
                  dashboard_data = json.load(f)

              # Strip both .json and .lvdash extensions
              clean_name = os.path.splitext(os.path.splitext(os.path.basename(dashboard_file))[0])[0]
              dashboard_data["display_name"] = clean_name

              # Step 1: Search for existing dashboards
              search_url = f"{host}/api/2.0/lakeview/dashboards"
              existing_dashboards = requests.get(search_url, headers=headers).json()

              # Step 2: Check if dashboard with same name exists
              existing_id = None
              for dash in existing_dashboards.get("dashboards", []):
                  if dash.get("display_name") == clean_name:
                      existing_id = dash.get("id")
                      break

              # Step 3: Delete if exists
              if existing_id:
                  delete_url = f"{host}/api/2.0/lakeview/dashboards/{existing_id}"
                  del_response = requests.delete(delete_url, headers=headers)
                  if del_response.status_code == 200:
                      print(f"🗑️ Deleted existing dashboard: {clean_name}")
                  else:
                      print(f"⚠️ Failed to delete existing dashboard: {del_response.text}")

              # Step 4: Create new dashboard
              create_url = f"{host}/api/2.0/lakeview/dashboards"
              response = requests.post(create_url, headers=headers, json=dashboard_data)
              if response.status_code in [200, 201]:
                  print(f"✅ Dashboard deployed successfully: {dashboard_file}")
              else:
                  print(f"❌ Failed to deploy dashboard {dashboard_file}: {response.text}")
          EOF

      - name: Create Git tag for release
        run: |
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git config --global user.name "github-actions[bot]"
          git tag "prod-deploy-$(date +'%Y-%m-%d-%H-%M')" -m "Deployed to production"
          git push origin --tags

      - name: Notify on success
        if: success()
        run: echo "✅ Deployment to production successful!"

      - name: Notify on failure
        if: failure()
        run: echo "❌ Deployment to production failed!"


