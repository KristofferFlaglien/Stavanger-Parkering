# This workflow triggers when code is pushed to the main branch
name: Deploy to Databricks Prod

on:
  push:
    branches:
      - main

jobs:
  deploy:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    env:
      DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
      DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}

    steps:
      - uses: actions/checkout@v3

      - name: Install Databricks CLI
        run: pip install --upgrade databricks-cli

      - name: Configure Databricks CLI
        run: |
          cat > ~/.databrickscfg << EOF
          [DEFAULT]
          host = ${{ secrets.DATABRICKS_HOST }}
          token = ${{ secrets.DATABRICKS_TOKEN }}
          EOF

      - name: Deploy notebooks to Databricks
        run: |
          set -euo pipefail
          for file in ./notebooks/*.ipynb; do
            echo "Deploying $file"
            filename=$(basename "$file" .ipynb)
            databricks workspace import "$file" "/Shared/${filename}_prod" -f SOURCE -l PYTHON --overwrite
          done

      - name: Deploy Lakeview dashboards (clean workspace first)
        run: |
          python3 - << 'EOF'
          import requests
          import json
          import os
          import glob

          host = os.environ['DATABRICKS_HOST']
          token = os.environ['DATABRICKS_TOKEN']

          headers = {
              'Authorization': f'Bearer {token}',
              'Content-Type': 'application/json'
          }

          dashboard_files = glob.glob('./dashboards/*.lvdash.json')

          for dashboard_file in dashboard_files:
              print(f"Deploying Lakeview dashboard: {dashboard_file}")
              with open(dashboard_file, 'r') as f:
                  dashboard_data = json.load(f)

              # Strip both .json and .lvdash extensions
              clean_name = os.path.splitext(os.path.splitext(os.path.basename(dashboard_file))[0])[0]
              dashboard_data["display_name"] = clean_name
              dashboard_data["parent_path"] = "/Shared"

              # Workspace path for the dashboard file
              workspace_path = f"/Shared/{clean_name}.lvdash.json"

              # Step 1: Delete existing dashboard file from workspace
              delete_url = f"{host}/api/2.0/workspace/delete"
              delete_payload = {"path": workspace_path}
              del_response = requests.post(delete_url, headers=headers, json=delete_payload)
              if del_response.status_code == 200:
                  print(f"🗑️ Deleted existing dashboard file at: {workspace_path}")
              elif del_response.status_code == 404:
                  print(f"ℹ️ No existing dashboard file to delete at: {workspace_path}")
              else:
                  print(f"⚠️ Failed to delete dashboard file: {del_response.text}")

              # Step 2: Create new dashboard
              create_url = f"{host}/api/2.0/lakeview/dashboards"
              response = requests.post(create_url, headers=headers, json=dashboard_data)
              if response.status_code in [200, 201]:
                  print(f"✅ Dashboard deployed successfully: {dashboard_file}")
              else:
                  print(f"❌ Failed to deploy dashboard {dashboard_file}: {response.text}")
          EOF

      - name: Create Git tag for release
        run: |
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git config --global user.name "github-actions[bot]"
          git tag "prod-deploy-$(date +'%Y-%m-%d-%H-%M')" -m "Deployed to production"
          git push origin --tags

      - name: Notify on success
        if: success()
        run: echo "✅ Deployment to production successful!"

      - name: Notify on failure
        if: failure()
        run: echo "❌ Deployment to production failed!"


