{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3682013f-28f8-4762-ba13-959c172ad3cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import row, col, to_date, hour, minute\n",
    "\n",
    "# Reload from silver\n",
    "df_cleaned = spark.table(\"default.parking_cleaned\")\n",
    "\n",
    "# lag dim_parkering\n",
    "\n",
    "# Hent eksisterende tabell hvis den finnes, ellers None\n",
    "existing_dim_parkering = spark.table(\"default.dim_parkering\") if \"default.dim_parkering\" in [t.name for t in spark.catalog.listTables(\"default\")] else None\n",
    "\n",
    "# Finn nye unike parkeringsplasser og gi kolonnene mer beskrivende navn\n",
    "new_dim_parkering = df_cleaned.select(\"Sted\", \"Latitude\", \"Longitude\").distinct()\n",
    "new_dim_parkering = new_dim_parkering.withColumnRenamed(\"Sted\", \"Parkering_navn\")\n",
    "\n",
    "\n",
    "# Bruk MERGE for å oppdatere dimensjonstabellen uten duplikater\n",
    "\n",
    "# gir lik funksjonalitet som å bruke DataFrame-basert delta merge med DeltaTable.forName(...).alias(...).merge(...)\n",
    "# kun forskjell i syntaks\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "MERGE INTO default.dim_parkering AS target\n",
    "USING (SELECT DISTINCT Sted AS Parkering_navn, Latitude, Longitude FROM default.staging_parking) AS source\n",
    "ON target.Parkering_navn = source.Parkering_navn\n",
    "WHEN NOT MATCHED THEN INSERT *\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# dim_tid\n",
    "\n",
    "# Bygg batch kun basert på nyeste data\n",
    "dim_tid_batch = df_cleaned.select(\n",
    "    to_date(\"timestamp\").alias(\"dato\"),\n",
    "    hour(\"timestamp\").alias(\"time\"),\n",
    "    minute(\"timestamp\").alias(\"minutt\")\n",
    ").distinct()\n",
    "\n",
    "\n",
    "# gjør tabellen tilgjengelig for Spark SQL\n",
    "dim_tid_batch.createOrReplaceTempView(\"new_dim_tid\")\n",
    "\n",
    "\n",
    "# MERGE for å legge til nye tidspunkter uten duplikater\n",
    "\n",
    "# # gir lik funksjonalitet som å bruke DataFrame-basert delta merge med DeltaTable.forName(...).alias(...).merge(...)\n",
    "# kun forskjell i syntaks\n",
    "# alle delta tables blir lest inn i Spark som DataFrames når man gjør spørringer på dem\n",
    "\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "MERGE INTO default.dim_tid AS target\n",
    "USING new_dim_tid AS source\n",
    "ON target.dato = source.dato AND target.time = source.time AND target.minutt = source.minutt\n",
    "WHEN NOT MATCHED THEN INSERT *\n",
    "\"\"\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_build_dims",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
