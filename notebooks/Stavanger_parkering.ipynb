{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71f52749-f532-46c3-975e-d6c9a73d9242",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Databricks Notebook: Komplett ETL-pipeline for parkeringsdata (uten Unity Catalog)\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Hent data fra ekstern URL\n",
    "# ------------------------------\n",
    "import requests\n",
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "from tests.etl_pipeline import sjekk_duplikater, valider_manglende, valider_gyldige_verdier, konverter_timestamp\n",
    "\n",
    "# Hent JSON-data fra en offentlig URL\n",
    "url = \"https://opencom.no/dataset/36ceda99-bbc3-4909-bc52-b05a6d634b3f/resource/d1bdc6eb-9b49-4f24-89c2-ab9f5ce2acce/download/parking.json\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# Konverter JSON-data til Spark DataFrame\n",
    "# (Datatypene blir automatisk inferert, men kan tilpasses manuelt ved behov)\n",
    "df_raw = spark.createDataFrame(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f997f647-5bdb-4b36-92a2-ac02c5fee674",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# 2. Kvalitetssikre data og konverter dato/klokkeslett\n",
    "# ----------------------------------------------------\n",
    "\n",
    "\n",
    "valider_manglende(df_raw) # sjekk at det ikke finnes manglende verdier å rådataene \n",
    "valider_gyldige_verdier(df_raw) # sjekk at verdiene er gyldige \n",
    "df_deduped = sjekk_duplikater(df_raw) # sjekk for duplikater\n",
    "df_cleaned = konverter_timestamp(df_deduped) # rens og konverter dato og klokkelett\n",
    "\n",
    "\n",
    "# df_cleaned er nå klar til å bli lagret i silver\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ef1b38f-919b-4a65-ae36-571bb7ffa8b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. Lagre staging-tabell (bronse)\n",
    "# ----------------------------------\n",
    "# Append for å bevare historiske data (bronse = ubehandlet rådata)\n",
    "bronze_path = \"/mnt/bronze/staging_parking\"\n",
    "df_raw.write.format(\"delta\").mode(\"append\").option(\"mergeSchema\", \"true\").save(bronze_path)\n",
    "spark.sql(f\"CREATE TABLE IF NOT EXISTS default.staging_parking USING DELTA LOCATION '{bronze_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e91ecb0-562f-4fb2-a4c9-7563548d6eb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------------------\n",
    "# 4. Dimensjonstabell: Parkering\n",
    "# ----------------------------------\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Hent eksisterende tabell hvis den finnes, ellers None\n",
    "existing_dim_parkering = spark.table(\"default.dim_parkering\") if \"default.dim_parkering\" in [t.name for t in spark.catalog.listTables(\"default\")] else None\n",
    "\n",
    "# Finn nye unike parkeringsplasser og gi kolonnene mer beskrivende navn\n",
    "new_dim_parkering = df_cleaned.select(\"Sted\", \"Latitude\", \"Longitude\").distinct()\n",
    "new_dim_parkering = new_dim_parkering.withColumnRenamed(\"Sted\", \"Parkering_navn\")\n",
    "\n",
    "# Vi antar at det alltid skal være nøyaktig 9 parkeringsplasser. Skriv bare hvis antallet ikke stemmer.\n",
    "if existing_dim_parkering is None or existing_dim_parkering.count() != 9:\n",
    "    new_dim_parkering.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"default.dim_parkering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "465af1e6-d787-4b32-b438-92ffe02495d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------------------\n",
    "# 5. Dimensjonstabell: Tid\n",
    "# ----------------------------------\n",
    "\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import to_date, hour, minute\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# Create an empty DataFrame with the same schema\n",
    "#empty_df = spark.createDataFrame([], spark.table(\"default.dim_tid\").schema)\n",
    "\n",
    "# Overwrite the table with empty data\n",
    "#empty_df.write.mode(\"overwrite\").saveAsTable(\"default.dim_tid\")\n",
    "\n",
    "\n",
    "# Bygg batch kun basert på nyeste data\n",
    "dim_tid_batch = df_cleaned.select(\n",
    "    to_date(\"timestamp\").cast(\"date\").alias(\"dato\"),\n",
    "    hour(\"timestamp\").cast(\"int\").alias(\"time\"),\n",
    "    minute(\"timestamp\").cast(\"int\").alias(\"minutt\")\n",
    ").distinct()\n",
    "\n",
    "# Sjekk om tabellen finnes\n",
    "if \"dim_tid\" in [t.name for t in spark.catalog.listTables(\"default\")]:\n",
    "    # Hent eksisterende tabell\n",
    "    existing_dim_tid = spark.table(\"default.dim_tid\").select(\"dato\", \"time\", \"minutt\")\n",
    "\n",
    "    # Finn tidspunkt som ikke finnes fra før\n",
    "    delta_tid = dim_tid_batch.join(existing_dim_tid, [\"dato\", \"time\", \"minutt\"], how=\"left_anti\")\n",
    "\n",
    "    # Legg til nye rader hvis noen er nye\n",
    "    if delta_tid.count() > 0:\n",
    "        delta_tid.write.format(\"delta\").mode(\"append\").saveAsTable(\"default.dim_tid\")\n",
    "else:\n",
    "    # Hvis tabellen ikke finnes, opprett den\n",
    "    dim_tid_batch.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"default.dim_tid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10965ebd-3416-4c55-bc14-9d5f59c37177",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------------------\n",
    "# 6. Faktatabell: Parkeringskapasitet\n",
    "# ----------------------------------\n",
    "from pyspark.sql.functions import to_date, hour, minute, date_format, to_timestamp, when, lit\n",
    "from pyspark.sql.functions import col, max as max_\n",
    "\n",
    "# Hent 9 observasjoner per kjøring (én per lokasjon)\n",
    "\n",
    "# spark.sql(\"TRUNCATE TABLE fakt_parkering\")\n",
    "\n",
    "new_fakt = df_cleaned.select(\n",
    "    to_date(\"timestamp\").alias(\"dato\"),\n",
    "    date_format(to_timestamp(\"timestamp\"), \"HH:mm\").alias(\"klokkeslett\"),  \n",
    "    \"Sted\",\n",
    "    \"Antall_ledige_plasser\",\n",
    "    \"timestamp\"\n",
    ")\n",
    "\n",
    "\n",
    "# Append for å lagre hver kjørings observasjoner\n",
    "new_fakt.write.format(\"delta\").mode(\"append\").option(\"mergeSchema\", \"true\").saveAsTable(\"default.fakt_parkering\")\n",
    "\n",
    "# Les tabellen på nytt, sorter og lagre tilbake\n",
    "df_sorted = spark.table(\"default.fakt_parkering\") \\\n",
    "    .orderBy(\"timestamp\", \"Sted\")\n",
    "\n",
    "df_sorted.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(\"default.fakt_parkering\")\n",
    "\n",
    "# fakt_parkering er nå gold-layer\n",
    "\n",
    "\n",
    "# Les eksisterende tabell, hent de 9 siste og sorter deretter\n",
    "latest9 = spark.table(\"default.fakt_parkering\") \\\n",
    "    .orderBy(col(\"timestamp\").desc()) \\\n",
    "    .limit(9) \\\n",
    "    .orderBy(col(\"Antall_ledige_plasser\").asc())\n",
    "\n",
    "\n",
    "# Lagre som ny tabell\n",
    "latest9.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"default.fakt_parkering_siste9\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b07f1a44-adef-46ad-a066-fdc35ff32ece",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "use catalog `hive_metastore`; select * from `default`.`fakt_parkering`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30636659-ea60-4e68-918d-2a091124130a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "use catalog `hive_metastore`; select * from `default`.`fakt_parkering_siste9` limit 100;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4616705994865846,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Stavanger_parkering",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
